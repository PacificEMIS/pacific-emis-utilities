{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26df7663-9832-4bf2-8fe7-f12e72dad5f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import configuration\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "def load_config(config_path=\"config.json\"):\n",
    "    \"\"\"Load configuration from a JSON file.\"\"\"\n",
    "    with open(config_path, 'r') as file:\n",
    "        config = json.load(file)\n",
    "    return config[\"sqlserver_name\"], config[\"sqlserver_db\"], config[\"sqlserver_ip\"], config[\"sqlserver_port\"], config[\"sqlserver_user\"], config[\"sqlserver_pwd\"], config['base_url'], config['username'], config['password'], config['output_directory'], config['cpd_directory']\n",
    "    \n",
    "\n",
    "# Test loading configuration\n",
    "sqlserver_name, sqlserver_db, sqlserver_ip, sqlserver_port, sqlserver_user, sqlserver_pwd, base_url, username, password, output_dir, cpd_directory = load_config()\n",
    "print(\"Configuration loaded successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5426a0f1-fff9-458b-b0ae-31f7e6b5b2ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Establish a database server connection\n",
    "import pyodbc\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "conn = \"\"\"\n",
    "    Driver={{ODBC Driver 17 for SQL Server}};\n",
    "    Server={},{};\n",
    "    Database={};\n",
    "    authentication=SqlPassword;UID={};PWD={};\n",
    "    TrustServerCertificate=yes;\n",
    "    \"\"\".format(sqlserver_ip, sqlserver_port, sqlserver_db, sqlserver_user, sqlserver_pwd)\n",
    "\n",
    "sql_conn = pyodbc.connect(conn, autocommit=False)\n",
    "\n",
    "cursor = sql_conn.cursor()\n",
    "cursor.execute('SELECT schNo, schName FROM Schools')\n",
    "\n",
    "for i, row in enumerate(cursor):\n",
    "    if i >= 3:\n",
    "        break\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbab8056-d86c-450b-a942-0ad613b307f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find excel workbook to load\n",
    "import os\n",
    "\n",
    "# Find CPD sample files to upload, skipping unwanted ones\n",
    "def find_sample_files(directory, skip_prefix=\"CPD-source-data-workbook\", extension=\".xlsx\"):\n",
    "    \"\"\"Scan directory and list files NOT starting with skip_prefix, matching extension.\"\"\"\n",
    "    files = []\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith(extension) and not filename.startswith(skip_prefix):\n",
    "            files.append(os.path.join(directory, filename))\n",
    "    return files\n",
    "\n",
    "# Load sample files\n",
    "sample_files = find_sample_files(cpd_directory)\n",
    "\n",
    "print(f\"Found {len(sample_files)} sample files to upload:\")\n",
    "for f in sample_files:\n",
    "    print(\"-\", os.path.basename(f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d850adcd-b5fa-492a-9617-2d3bbb137bf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all excel workbook in memory.\n",
    "import openpyxl\n",
    "\n",
    "# Load all Excel files into memory (workbooks)\n",
    "def load_excel_workbooks(file_list):\n",
    "    \"\"\"Load Excel workbooks into memory.\"\"\"\n",
    "    workbooks = {}\n",
    "    for file_path in file_list:\n",
    "        try:\n",
    "            wb = openpyxl.load_workbook(file_path)\n",
    "            workbooks[file_path] = wb\n",
    "            print(f\"‚úÖ Loaded: {os.path.basename(file_path)}\")\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Failed to load {os.path.basename(file_path)}: {e}\")\n",
    "    return workbooks\n",
    "\n",
    "# Actually load them now\n",
    "all_workbooks = load_excel_workbooks(sample_files)\n",
    "\n",
    "print(f\"\\nTotal workbooks loaded: {len(all_workbooks)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b29da96e-7e48-4038-a56f-a6977cebf43c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert Excel workbook data into XML\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "def workbook_to_xml(wb):\n",
    "    ws = wb[\"CPD data\"]  # your sheet is called exactly \"CPD data\"\n",
    "\n",
    "    # Build a list of column headers\n",
    "    headers = []\n",
    "    for cell in ws[1]:\n",
    "        if cell.value is not None:\n",
    "            headers.append(cell.value.strip())\n",
    "        else:\n",
    "            headers.append(\"\")\n",
    "\n",
    "    # Column mapping (your provided one)\n",
    "    column_mapping = {\n",
    "        \"CPD Name\": \"CPDName\",\n",
    "        \"CPD Format\": \"CPDFormat\",\n",
    "        \"CPD Focus\": \"CPDFocus\",\n",
    "        \"Location\": \"Location\",\n",
    "        \"Year\": \"Year\",\n",
    "        \"Start Date (YYY-MM-DD)\": \"StartDate\",\n",
    "        \"End Date (YYY-MM-DD)\": \"EndDate\",\n",
    "        \"Duration in Days\": \"DurationDays\",\n",
    "        \"Duration in Hours\": \"DurationHours\",\n",
    "        \"Teacher PF Number\": \"TeacherPFNumber\",\n",
    "        \"Teacher First Name\": \"TeacherFirstName\",\n",
    "        \"Teacher Last Name\": \"TeacherLastName\",\n",
    "        \"Gender\": \"Gender\",\n",
    "        \"Disability\": \"Disability\",\n",
    "        \"Approximate Years Teaching\": \"ApproximateYearsTeaching\",\n",
    "        \"Attendance Rate\": \"AttendanceRate\",\n",
    "        \"80% Attendance\": \"Percent80Attendance\",\n",
    "        \"Statement of Completion\": \"StatementCompletion\",\n",
    "        \"School\": \"School\"\n",
    "    }\n",
    "    # Add attended day columns dynamically\n",
    "    for i in range(1, 16):\n",
    "        column_mapping[f\"Attended Day {i}\"] = f\"AttendedDay{i}\"\n",
    "\n",
    "    # Root element\n",
    "    root = ET.Element(\"ListObject\")\n",
    "    root.set(\"FirstRow\", \"2\")\n",
    "\n",
    "    # Set cpdName and cpdYear attributes\n",
    "    first_data_row = list(ws.iter_rows(min_row=2, max_row=2, values_only=True))[0]\n",
    "    header_to_index = {h: i for i, h in enumerate(headers)}\n",
    "    root.set(\"cpdName\", str(first_data_row[header_to_index[\"CPD Name\"]]))\n",
    "    root.set(\"cpdYear\", str(int(first_data_row[header_to_index[\"Year\"]])))\n",
    "\n",
    "    # Build rows\n",
    "    for idx, row in enumerate(ws.iter_rows(min_row=2, values_only=True)):\n",
    "        if all(cell is None for cell in row):\n",
    "            continue  # Skip blank rows\n",
    "        \n",
    "        row_elem = ET.SubElement(root, \"row\")\n",
    "        row_elem.set(\"Index\", str(idx))\n",
    "        for header, cell_value in zip(headers, row):\n",
    "            if not header:\n",
    "                continue  # Skip empty headers\n",
    "            \n",
    "            xml_attr = column_mapping.get(header)\n",
    "            if xml_attr:\n",
    "                if header in [\"Start Date (YYY-MM-DD)\", \"End Date (YYY-MM-DD)\"]:\n",
    "                    if cell_value is not None:\n",
    "                        # Convert dates to Excel serial number\n",
    "                        val = (cell_value - datetime(1899, 12, 30)).days\n",
    "                    else:\n",
    "                        val = \"\"\n",
    "                else:\n",
    "                    val = cell_value if cell_value is not None else \"\"\n",
    "                \n",
    "                row_elem.set(xml_attr, str(val).strip())\n",
    "\n",
    "    return ET.tostring(root, encoding=\"unicode\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64fce511-c851-4afa-b8a8-ea4f5fb8cb04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print out one generated XML\n",
    "somefile = next(iter(all_workbooks.keys()))\n",
    "print(workbook_to_xml(all_workbooks[somefile]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87b2d527-56a9-4731-87fe-281958cc5366",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code to process the Excel workbook into XML data ready for SQL server stored proc\n",
    "import uuid\n",
    "import pyodbc\n",
    "\n",
    "def extract_cpd_metadata(wb):\n",
    "    \"\"\"Extract CPD Name and CPD Year from the workbook.\"\"\"\n",
    "    # Access the 'CPD data' sheet\n",
    "    ws = wb[\"CPD data\"]\n",
    "\n",
    "    # Read the first data row (row 2)\n",
    "    first_row = [cell.value for cell in ws[2]]\n",
    "\n",
    "    # Read headers from row 1\n",
    "    headers = [cell.value for cell in ws[1]]\n",
    "\n",
    "    # Create dictionary of {column name -> value}\n",
    "    row_dict = dict(zip(headers, first_row))\n",
    "\n",
    "    # Extract CPD Name and Year\n",
    "    cpd_name = row_dict.get(\"CPD Name\", \"\")\n",
    "    cpd_year = row_dict.get(\"Year\", \"\")\n",
    "\n",
    "    if not cpd_name or not cpd_year:\n",
    "        raise ValueError(f\"Missing CPD Name or Year in workbook {wb.properties.title}.\")\n",
    "\n",
    "    return cpd_name, cpd_year\n",
    "\n",
    "import base64\n",
    "\n",
    "def load_single_workbook_to_sql(file_path, sql_conn):\n",
    "    wb = all_workbooks[file_path]\n",
    "    xml_data = workbook_to_xml(wb)\n",
    "    \n",
    "    cpd_name, cpd_year = extract_cpd_metadata(wb)\n",
    "    file_reference = str(uuid.uuid4())\n",
    "    username = \"ghachey@purltek.com\"\n",
    "    cpd_code = cpd_name\n",
    "\n",
    "    # Encode XML\n",
    "    xml_base64 = base64.b64encode(xml_data.encode('utf-8')).decode('ascii')\n",
    "\n",
    "    query = f\"\"\"\n",
    "    DECLARE @p1 XML;\n",
    "    DECLARE @bin VARBINARY(MAX);\n",
    "\n",
    "    SET @bin = CAST(CAST('{xml_base64}' AS XML).value('.', 'VARBINARY(MAX)') AS VARBINARY(MAX));\n",
    "    SET @p1 = CONVERT(XML, @bin);\n",
    "\n",
    "    EXEC pTeacherWrite.LoadTeacherCpd \n",
    "        @cpdData = @p1, \n",
    "        @fileReference = '{file_reference}',\n",
    "        @user = '{username}',\n",
    "        @cpdCode = '{cpd_code}',\n",
    "        @cpdYear = {cpd_year};\n",
    "    \"\"\"\n",
    "\n",
    "    cursor = sql_conn.cursor()\n",
    "    cursor.execute(query)\n",
    "\n",
    "    # üìå Important: advance through ALL possible result sets\n",
    "    while cursor.nextset():\n",
    "        pass\n",
    "\n",
    "    sql_conn.commit()\n",
    "    cursor.close()\n",
    "\n",
    "    print(f\"‚úÖ Successfully loaded {os.path.basename(file_path)} into SQL Server.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d32c5cd6-0dcd-47a5-b0cd-47e18f643d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try loading a single workbook in DB\n",
    "somefile = list(all_workbooks.keys())[1] # change index to load load different one\n",
    "print(f\"Loading file: {os.path.basename(somefile)}\")\n",
    "\n",
    "# Run the loader\n",
    "load_single_workbook_to_sql(somefile, sql_conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e7ee3ec-dee8-4dab-9a8f-4aeb0b5c9393",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bulk load all workbooks to SQL Server\n",
    "import time\n",
    "\n",
    "def bulk_load_all_workbooks(all_workbooks, sql_conn, verbose=True):\n",
    "    total = len(all_workbooks)\n",
    "    success_count = 0\n",
    "    fail_count = 0\n",
    "    start_time = time.time()\n",
    "\n",
    "    for idx, file_path in enumerate(all_workbooks.keys(), start=1):\n",
    "        try:\n",
    "            print(f\"({idx}/{total}) Loading: {os.path.basename(file_path)} ...\", end=\" \")\n",
    "            load_single_workbook_to_sql(file_path, sql_conn)\n",
    "            success_count += 1\n",
    "            if verbose:\n",
    "                print(\"‚úÖ\")\n",
    "        except Exception as e:\n",
    "            fail_count += 1\n",
    "            print(f\"‚ùå Failed: {e}\")\n",
    "\n",
    "    duration = time.time() - start_time\n",
    "    print(\"\\n=== Bulk Load Summary ===\")\n",
    "    print(f\"Total Files Attempted : {total}\")\n",
    "    print(f\"‚úÖ Success             : {success_count}\")\n",
    "    print(f\"‚ùå Failed              : {fail_count}\")\n",
    "    print(f\"‚è±Ô∏è Duration           : {duration:.2f} seconds\")\n",
    "\n",
    "# Run it:\n",
    "bulk_load_all_workbooks(all_workbooks, sql_conn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcc59704-6191-4842-b81b-99210fb69180",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,auto:percent"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
